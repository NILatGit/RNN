{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Single Cell"
      ],
      "metadata": {
        "id": "jlHzJINDL0DU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where:\n",
        "- $x_t$​: input at time t\n",
        "- $h_t$​: hidden state at time t    \n",
        "- $W_{ih}$​: input → hidden weights\n",
        "- $W_{hh}$​: hidden → hidden weights\n",
        "- $W_{ho}$​: hidden → output weights"
      ],
      "metadata": {
        "id": "jxMTcR9HMPmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "h_t = \\tanh(W_{ih} \\cdot x_t + W_{hh} \\cdot h_{t-1} + b)\\tag{input for next state}\n",
        "$$"
      ],
      "metadata": {
        "id": "6n3W3i31MWrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "y_t= W_{ho} \\cdot h_t + c\\tag{output}\n",
        "$$"
      ],
      "metadata": {
        "id": "bVSm-r9dMZr6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y97rlHt1bPh0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 50   # vocabulary size\n",
        "hidden_size = 128\n",
        "output_size = 50  # same as vocab size\n",
        "seq_length = 10\n",
        "batch_size = 1\n",
        "\n",
        "# Parameters with gradient tracking\n",
        "W_ih = torch.randn(input_size, hidden_size, requires_grad=True) * 0.01\n",
        "W_hh = torch.randn(hidden_size, hidden_size, requires_grad=True) * 0.01\n",
        "b_h = torch.zeros(hidden_size, requires_grad=True)\n",
        "\n",
        "W_ho = torch.randn(hidden_size, output_size, requires_grad=True) * 0.01\n",
        "b_o = torch.zeros(output_size, requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Forward Pass"
      ],
      "metadata": {
        "id": "Z4RgiRtALvvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random input sequence: batch_size x seq_len x input_size (one-hot vectors)\n",
        "x_seq = F.one_hot(torch.randint(0, input_size, (seq_length,)), num_classes=input_size).float()\n",
        "\n",
        "h_t = torch.zeros(hidden_size)  # Initial hidden state\n",
        "\n",
        "outputs = []\n",
        "for t in range(seq_length):\n",
        "    x_t = x_seq[t]\n",
        "    h_t = torch.tanh(x_t @ W_ih + h_t @ W_hh + b_h)\n",
        "    y_t = h_t @ W_ho + b_o\n",
        "    outputs.append(y_t)\n",
        "\n",
        "# Stack outputs into shape: (seq_len, output_size)\n",
        "logits = torch.stack(outputs)"
      ],
      "metadata": {
        "id": "Pg3IAU6RLsld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Calculation"
      ],
      "metadata": {
        "id": "leA66YggL6-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random target (e.g. next char)\n",
        "target = torch.randint(0, input_size, (seq_length,))\n",
        "loss = F.cross_entropy(logits, target)\n",
        "\n",
        "# Backpropagation\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "-8JYVyF4L6oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "-nRIqpMXMBWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "for param in [W_ih, W_hh, b_h, W_ho, b_o]:\n",
        "    param.data -= lr * param.grad\n",
        "    param.grad.zero_()"
      ],
      "metadata": {
        "id": "LrLE80qXMFqr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}